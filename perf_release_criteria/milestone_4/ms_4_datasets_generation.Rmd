---
title: 'Milestone 4: Datasets Generation'
output:
  html_notebook:
    theme: cosmo
    toc: yes
    toc_float: yes
date: 'Last Updated: `r format(Sys.time(), "%B %d, %Y")`'
---

```{r imports, echo=FALSE, warning=FALSE, message=FALSE}
source('../lib/supporting_funcs.R')
library(bigrquery)
library(DBI)
```

# tl;dr 
This notebook generates the training (Version N) and prediction (Version N+1) datasets used for measuring Release performance  [PRD](https://docs.google.com/document/d/1Ygz6MkudYHZjnDnD9Z97kUyFrvV3KGWsjXyPjddhHq0/edit#heading=h.lvb9l8gw2nee). The training dataset is used to train a stastical matching model, which then is used to find a subset of Beta profiles. These profiles are then used in the prediction dataset to calculate the various performance metrics. 

# Dataset Preparation
The datasets are generated by this [notebook](
https://storage.cloud.google.com/moz-fx-data-bq-data-science-cdowhygelund/notebooks/jupyter/Beta_Release_Subsetting_Data_Preparation_GCP.ipynb
) on a Dataproc cluster. These are serialized as BigQuery tables available in the `moz-fx-data-shared-prod.analysis` dataset as `cdowhygelund_subBeta_training` (Version N) and `cdowhygelund_subBeta_prediction` (Version N+1). 

# Covariate Generation
The following process is very similar to that used in the validation of the [proof-of-concept](https://metrics.mozilla.com/protected/cdowhygelund/beta_subset_release_validation.html). In addition:

* `na.omit` is not applied.
* Missing values are only dropped for the performance metrics (outcomes) of concern
* OS is filtered to only Windows. 

```{r gcp_connect, echo=FALSE}
project <- "moz-fx-dev-cdowhyglund-subbeta"

con <- dbConnect(
  bigrquery::bigquery(),
  project = 'moz-fx-data-shared-prod',
  dataset = 'analysis',
  billing = project
)
```

```{r var_defs, echo=FALSE}
# outcomes <- c('TIME_TO_DOM_INTERACTIVE_MS', 'TIME_TO_DOM_CONTENT_LOADED_END_MS', 'TIME_TO_LOAD_EVENT_END_MS', 
#               'TIME_TO_NON_BLANK_PAINT_MS', 'TIME_TO_DOM_COMPLETE_MS', 'FX_PAGE_LOAD_MS_2_PARENT') (FIXME)

outcomes <- c('TIME_TO_DOM_CONTENT_LOADED_END_MS', 'TIME_TO_LOAD_EVENT_END_MS', 'TIME_TO_DOM_COMPLETE_MS', 'FX_PAGE_LOAD_MS_2_PARENT') 

# define response field
label <- 'is_release'
```

```{r data_prep}
load_df <- function(table){
  df <- tbl(con, table) %>%
#     filter(locale %in% c('en-US', 'en-GB')) %>%  (FIXME)
    filter(country %in% c('US', 'GB')) %>%
    filter(os == 'Windows_NT') %>%
    collect() %>%
    # mutate(client_id = as.character(client_id)) %>%
    select(-os, country) %>%
    drop_na(outcomes) %>%
    mutate(default_search_engine = as.factor(normalize_search_engine(default_search_engine))) %>%
    mutate(profile_age_cat = as.factor(normalize_profile_age(profile_age))) %>%
    mutate(distro_id_norm = as.factor(normalize_distro_id(distribution_id))) %>%
    mutate(timezone_cat = as.factor(normalize_timezone(timezone_offset))) %>%
    mutate(memory_cat = as.factor(normalize_memory(memory_mb))) %>% 
    mutate(cpu_speed_cat = as.factor(normalize_cpu_speed(cpu_speed_mhz))) %>% 
    mutate(cpu_cores_cat = as.factor(normalize_cpu_cores(cpu_cores))) %>% 
    mutate(!!label := case_when(
      label == 'beta' ~ FALSE,
      TRUE ~ TRUE)) %>%
    filter(startup_ms >= 0 & profile_age >= 0)
}

df_train <- load_df("cdowhygelund_subBeta_training")
df_validate <- load_df('cdowhygelund_subBeta_prediction')
```

# Review 

```{r summarize}
summary(df_train)
```

## Observations

These observations were noted previously during Milestone 2 (`ms_2_datasets_generation.Rmd`). Noting here now for completeness.
* Content crashes looks strange. Always is 0. Not sure what happened there...
    - Appears to always be 0 
    - **Action**: Remove it
* Categories for `cpu_vendor`, and `os_version` have several low populated categories
    - Remap these categories to "Other"
* `city`, `geo_subdivision1`, and  `geo_subdivision2` are dominated by "other" categories.
    - **Action**: Remove them
*  `cpu_l3_cache_kb` and `cpu_stepping` have large number of NA's
    - **Action**: Remove them
*  `cpu_model` and `cpu_family` appear to be subcategories of `cpu_family`.
    - **Action**: Remove for modeling. 
    - **However**: These could (and other cpu fields) be added in for use in validation and slicing/segmentation.
* 'distribution_id` is redundant with `distro_id_norm`
    - **Action**: Remove it
* `cpu_l2_cache_kb` has a small number of NA
    - **Action**: Drop these rows as they are very small fraction. 
    - **Action**: Create a categorical variable to reflect other environment covariates.
* `install_year` and `profile_age` have unrealistic values
    - **Action**: Filter them out. `install_year` between 1990 and now. Profiles younger than 20 years. 
* `startup_ms` has crazy times
    - **Action**: The top 0.001% are being filtered already. Review to determine how these change with matching on performance metrics.
* Drop unused factors on `default_search_engine`, `is_wow64` 


## Duplicate clients 
Find number of clients that are both in Beta and Release. This isn't a problem per se, it is just an interesting observation. 

```{r}
df_train %>% count(client_id) %>% select(n) %>% table
```

Duplicate cients are really uncommon!

## Cleaning

Performing the proposed actions above

```{r cleaning, echo=FALSE, message=FALSE, warning=FALSE}
normalize_os_version <- function(os_version){
  levels <- c('Other', '6.1', '6.2', '6.3', '10.0')
  factor(
    case_when(
      os_version == '10.0' ~ levels[5],
      os_version == '6.3' ~ levels[4],
      os_version == '6.2' ~ levels[3],
      os_version == '6.1' ~ levels[2],
      TRUE ~ levels[1]
    ), levels = levels, ordered = TRUE
  )
}

normalize_cpu_vendor <- function(cpu_vendor){
  factor(
    case_when(
      cpu_vendor == 'AuthenticAMD' ~ 'AMD',
      cpu_vendor == 'GenuineIntel' ~ 'Intel',
      TRUE ~ 'Other'
    )
  )
}

normalize_cpu_l2_cache <- function(cpu_l2_cache){
  levels <- c('< 256', '< 512', '< 768', '< 1024', '> 1024')
  factor(
    case_when(
      cpu_l2_cache <= 256 ~ levels[1],
      cpu_l2_cache <= 512 ~ levels[2],
      cpu_l2_cache <= 768 ~ levels[3],
      cpu_l2_cache <= 1024 ~ levels[4],
      TRUE ~ levels[5]
    )
  )
}

stage_2_clean <- function(df){
  df_clean <- df %>%
    select(-c(city, geo_subdivision1, geo_subdivision2, cpu_l3_cache_kb, cpu_stepping, 
              cpu_model, cpu_family, distribution_id)) %>%
    filter(between(install_year, 1991, 2019)) %>%
    filter(profile_age <= 365 * 20 ) %>%
    na.omit() %>% 
    mutate(os_version = normalize_os_version(os_version)) %>%
    mutate(cpu_vendor = normalize_cpu_vendor(cpu_vendor)) %>%
    mutate(cpu_l2_cache_kb_cat = normalize_cpu_l2_cache(cpu_l2_cache_kb)) %>%
    droplevels()
  return(df_clean)
}

df_train_f <- stage_2_clean(df_train)
df_validate_f <- stage_2_clean(df_validate)

```

```{r}
summary(df_train_f)
```

# Modeling Dataset

The optimal modeling dataset utilized an 4x oversampling of Beta with respect to Release. 

```{r training_oversample}
oversample <- function(df_c, oversampling){
  df_beta <- df_c %>% filter(is_release == FALSE)
  df_rel <- df_c %>% filter(is_release == TRUE)
  n_beta <- nrow(df_beta)
  
  model_ids <- df_rel %>%
    sample_n(size = round(n_beta / oversampling)) %>%
    rbind(df_beta) %>%
    pull(client_id)
  
  return(df_c %>% filter(client_id %in% model_ids))
}

df_train_x <- oversample(df_train_f, oversampling = 4)
```


# Serialize and push to GCP
Save the resultant dataset and bootstrap samples to an R image. 

```{r serialize_dataset}
image_file_name <- paste('df_train_', format(Sys.time(), "%Y%m%d"), '.RData', sep='')
image_file_path <- file.path('data', image_file_name)
save(df_train_f, df_validate_f, df_train_x, file = image_file_path)

gcs_file_path <- file.path('data', 'milestone4', image_file_name)
```

Then push the results to GCP in the `moz-fx-dev-subbeta` bucket, under `r gcs_file_path`.

```{r gcp_storage_push, warning=FALSE}
Sys.setenv("GCS_DEFAULT_BUCKET" = "moz-fx-dev-subbeta",
           "GCS_AUTH_FILE" = "~/certs/moz-fx-dev-cdowhyglund-subBeta-788f8f0d4627.json")

library(googleCloudStorageR)

upload_try <- gcs_upload(image_file_path, name = gcs_file_path)
upload_try
```


