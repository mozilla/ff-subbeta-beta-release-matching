---
title: "Milestone 2: Feature Selection - Genetic Matching, Logit, with Linear Propensity Score"
author: "Corey Dow-Hygelund, Mozilla Data Science"
date: 'Last Updated: `r format(Sys.time(), "%B %d, %Y")`'
output: 
  html_notebook:
    theme: cosmo
    toc: true
    toc_float: true
---

# tl;dr

This analysis determines the relevant [covariates (features)](https://docs.google.com/document/d/1SfuanvmYmvmEFAdQ7Z5djDeLezdNB1TESqVmj93O8to/edit#heading=h.nwwrif453n80) to utilize for computationally intensive statistical matching algorithms proposed in the modeling approach for this [PRD](https://docs.google.com/document/d/1Ygz6MkudYHZjnDnD9Z97kUyFrvV3KGWsjXyPjddhHq0/edit#heading=h.lvb9l8gw2nee). 

**Matching Algorithm Tested**: Genetic Matching with logit distance metric transformed back to linear scale

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
knitr::opts_knit$set(root.dir = dirname(getwd()))
```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(Matching)
source('../lib/supporting_funcs.R')
source('../lib/scoring.R')
```





```{r data_load, echo=FALSE}
file_name = 'df_train_validate_20191025.RData'
image_file_path = file.path('data', file_name)

# Pull from GCP if necessary
if (!file.exists(image_file_path)){
  Sys.setenv("GCS_DEFAULT_BUCKET" = "moz-fx-dev-subbeta",
           "GCS_AUTH_FILE" = "moz-fx-dev-cdowhyglund-subBeta-788f8f0d4627.json")
  library(googleCloudStorageR)
  gcs_get_object(file.path('data', 'milestone2', file_name), saveToDisk = image_file_path, overwrite = TRUE)

}
load(image_file_path)
```

```{r bts, echo=FALSE}
bts = list(
  bts_1x = bts.1x,
  bts_4x = bts.4x,
  bts_8x = bts.8x,
  bts_16x = bts.16x
)

perf_metrics <- names(get_m2_metric_map())

covs <- df_train_f %>%
  select(-perf_metrics) %>%
  select(-content_crashes) %>%
  select(-client_id) %>%
  select(-label) %>%
  select(-is_release) %>%
  select(-app_version) %>%
  select_if(is.numeric) %>% # Mahalanobis constraint
  names()
  

results_file_name <- 'feature_selection_genmatch_.RData' 
results_file_path <- file.path('data', results_file_name)
```

# Features

Feature sets: 

1. Only performance metrics.
2. Performance metrics and the highest found by Boruta with original dataset.
3. Performance metrics and the highest found by Boruta with equal labels dataset.
4. Performance metrics and all covariates.
5. Only the highest covariates found by Boruta (excluding performance).
6. Only the highest covariates found by Boruta (equal labels, excluding performance).
7. Utilize all covariates (excluding performance). 

Retrieve Boruta features:

```{r boruta_import}
file_name = 'feature_selection_boruta_initial_20191023.RData'
image_file_path = file.path('data', file_name)

if(!file.exists(image_file_path)){
  Sys.setenv("GCS_DEFAULT_BUCKET" = "moz-fx-dev-subbeta",
             "GCS_AUTH_FILE" = "moz-fx-dev-cdowhyglund-subBeta-788f8f0d4627.json")
  library(googleCloudStorageR)
  gcs_get_object(file.path('data', 'milestone2', file_name), saveToDisk = image_file_path, overwrite = TRUE)
}

load(image_file_path)
```

```{r boruta_fs}
extract_boruta_fs <- function(boruta_res, num=5){
  features <- NULL
  for(metric in names(boruta_results)){
    features <- c(names(sort(apply(boruta_res[[metric]]$ImpHistory, 2, median), decreasing = TRUE)[1:num]), features)
  }
  return(sort(unique(features)))
}

features_top10 <- extract_boruta_fs(boruta_results, num=10)
features_top10_eq <- extract_boruta_fs(boruta_results_eq, num=10)

# filter out categorical
features_top10 <- df_train_f %>% select(features_top10) %>% select_if(is.numeric) %>% names()
features_top10_eq <- df_train_f %>% select(features_top10_eq) %>% select_if(is.numeric) %>% names()
```

```{r feature_sets}
fs1 <- perf_metrics
fs2 <- c(names(fs1), features_top10)
fs3 <- c(names(fs1), features_top10_eq)
fs4 <- c(names(fs1), covs)
fs5 <- features_top10
fs6 <- features_top10_eq
fs7 <- covs
```

# Dataset
Due to the computationally intensive nature of Genetic Matching, a single run for each set will be utilized. This is a compromise due to the deisre to utilize appropriately size datasets, and investigating feature sets. The training set will be equalized in size, with the excluded release profiles used for scoring.

```{r dataset_gen}
df_beta <- df_train_f %>%
  filter(label == 'beta')
set.seed(20191030)
df_rel <- df_train_f %>%
  filter(label == 'release') %>%
  sample_n(size = nrow(df_beta)-100)

set.seed(20191030)
df_train_gen <- df_beta %>%
  bind_rows(df_rel) %>%
  sample_n(size = 90000)

df_test_gen <- df_train_f %>%
  filter(label == 'release') %>%
  filter(!client_id %in% df_train_gen$client_id)
```

```{r}
run_genmatch_sample <- function(df_train, df_test, model_covs, ...){
  workers = detectCores()
  
  # train model 
  gen1 <- GenMatch(Tr = df_train$is_release, X = df_train[, model_covs], 
                   cluster = rep('localhost', workers), ...)
  mgen1 <- Match(Y = NULL, Tr = df_train$is_release, X = df_train[, model_covs], Weight.matrix = gen1)
  
  
  # extract matched dataframe
  df_matched <- df_train[mgen1$index.control,]

  # build dataframe for scoring
  df_scored <- df_matched %>%
    bind_rows(df_test)

  #apply scoring
  return(list(
    score = calc_score(df_scored, get_m2_metric_map()), 
    model = gen1, 
    matches = mgen1)
    )
}
```


# FS 1
Feature selection on only performance metrics 

```{r}
fs1_results <- run_genmatch_sample(df_train_gen, df_test_gen, perf_metrics, pop.size = 100, ties = FALSE)
save(list=ls(pattern = 'fs[0-9]_results'),  file = results_file_path)
fs1_results$score
```

## Pop.Size = 500

```{r}
fs1_500_results <- run_genmatch_sample(df_train_gen, df_test_gen, perf_metrics, pop.size = 500, ties = FALSE)
save(list=ls(pattern = 'fs[0-9]_results'),  file = results_file_path)
fs1_500_results$score
```

## nboots = 10
```{r}
fs1_nboots_results <- run_genmatch_sample(df_train_gen, df_test_gen, perf_metrics, 
                                   pop.size = 100, nboots = 10, ties = FALSE)
# save(list=ls(pattern = 'fs[0-9]_results'),  file = results_file_path)
fs1_nboots_results$score
```

# FS 3
```{r fs_3}
fs3_results <- run_genmatch_sample(df_train_gen, df_test_gen, fs3, pop.size = 100, ties = FALSE)
save(list=ls(pattern = 'fs[0-9]_results'),  file = results_file_path)
fs3_results$score
```


# FS 5
```{r fs_5}
fs5_results <- run_genmatch_sample(df_train_gen, df_test_gen, fs5, pop.size = 100, ties = FALSE)
save(list=ls(pattern = 'fs[0-9]_results'),  file = results_file_path)
fs5_results$score
```

```{r serialize_results}
save(list=c('df_train_gen', 'df_test_gen', ls(pattern = 'fs[0-9]')),  file = results_file_path)
```


**TODO**:
1. Adding in propensity score

# Push to GCP
Save the resultant dataset and bootstrap samples to an R image. 

```{r gcp_storage_push, warning=FALSE}
gcs_file_path <- file.path('data', 'milestone2', results_file_name)

Sys.setenv("GCS_DEFAULT_BUCKET" = "moz-fx-dev-subbeta",
           "GCS_AUTH_FILE" = "moz-fx-dev-cdowhyglund-subBeta-788f8f0d4627.json")

library(googleCloudStorageR)

upload_try <- gcs_upload(results_file_path, name = gcs_file_path)
upload_try
```

